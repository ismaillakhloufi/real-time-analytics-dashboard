# Projet : Tableau de Bord d'Analytique en Temps R√©el avec Apache Spark et Kafka

## Architecture du Projet
![Architecture du Projet](architecture.jpeg)

---

## Aper√ßu du Projet
Dans ce projet, nous avons d√©velopp√© un pipeline d'analytique en temps r√©el qui traite des flux de donn√©es en direct, tels que les cours boursiers. En utilisant **Apache Kafka** pour l'ingestion des donn√©es et **Apache Spark** pour le traitement en temps r√©el, les donn√©es sont trait√©es en continu et visualis√©es dans un tableau de bord en direct (utilisant **Grafana**).

L'objectif de ce projet est de d√©montrer la capacit√© √† g√©rer des donn√©es en temps r√©el, √† les traiter efficacement et √† pr√©senter des insights actionnables visuellement. Le r√©sultat final est un tableau de bord enti√®rement fonctionnel qui se met √† jour au fur et √† mesure que les donn√©es arrivent, fournissant des insights imm√©diats comme les tendances des cours boursiers.

---

## √âtapes Impliqu√©es

### 1. üöÄ Ingestion des Donn√©es avec Apache Kafka
- **Kafka** sert de syst√®me pour le streaming de donn√©es en temps r√©el. Il permet l'int√©gration facile de diverses sources de donn√©es, telles que les cours boursiers via Yahoo Finance.
- Un **producteur Kafka** pousse continuellement les donn√©es en direct dans un topic Kafka, tandis qu'un **consommateur Kafka** tire les donn√©es pour un traitement ult√©rieur.

### 2. ‚öôÔ∏è Traitement des Donn√©es en Temps R√©el avec Apache Spark
- **Spark** est utilis√© pour effectuer des t√¢ches de traitement de donn√©es en temps r√©el, telles que le calcul des moyennes mobiles ou le nettoyage des donn√©es.
- **Spark Streaming**, un composant de Spark, permet le calcul continu, permettant ainsi le traitement des donn√©es d√®s qu'elles sont ing√©r√©es depuis Kafka.
- Exemples de t√¢ches de traitement :
  - Pour les cours boursiers : calcul des moyennes de prix sur une fen√™tre de 1 minute.

### 3. üìä Visualisation des Donn√©es avec un Tableau de Bord
- Un tableau de bord en direct est cr√©√© en utilisant **Grafana** pour visualiser les donn√©es trait√©es.
- Le tableau de bord refl√®te les mises √† jour en temps r√©el, affichant les tendances des donn√©es, les analyses et d'autres m√©triques utiles √† l'utilisateur.
- Exemples de visualisations :
  - Un graphique lin√©aire montrant les changements de prix des actions au fil du temps.

---

## Probl√®mes Potentiels et Solutions
- **Gestion de la Perte de Donn√©es** : Dans le streaming en temps r√©el, il y a un risque de perte de donn√©es lors des d√©faillances. Pour g√©rer cela, nous utilisons les fonctionnalit√©s tol√©rantes aux pannes de Kafka et activons le checkpointing de Spark pour assurer la r√©cup√©ration apr√®s une d√©faillance.
- **Mise √† l'√âchelle** : Si le jeu de donn√©es augmente ou si les flux de donn√©es deviennent trop volumineux pour une machine locale, envisagez d'optimiser les configurations de Spark et Kafka, ou d'utiliser un √©chantillon de donn√©es plus petit √† des fins de d√©monstration.

---

## Alternatives d'Acquisition de Donn√©es
- **Donn√©es R√©elles** : Nous avons connect√© Yahoo Finance pour les cours boursiers en temps r√©el. Ces sources fournissent d'excellents exemples de flux de donn√©es rapides qui sont parfaits pour le traitement en temps r√©el.
- **Donn√©es Simul√©es** : Si l'acc√®s aux API en direct est restreint (en raison de limites ou de co√ªts), vous pouvez simuler des flux de donn√©es en utilisant des scripts Python. Cette m√©thode vous permettra de contr√¥ler le flux de donn√©es et de reproduire un environnement de streaming en temps r√©el.

---

## Outils Alternatifs
- Si vous rencontrez des probl√®mes avec Kafka et Spark, vous pourriez utiliser des alternatives telles qu'**Apache Flink** pour le traitement de flux ou **RabbitMQ** pour le courtage de messages au lieu de Kafka. De m√™me, le tableau de bord pourrait √™tre construit en utilisant **Power BI** si Grafana ne convient pas √† vos besoins.

---

## R√©sultat du Projet
√Ä la fin de ce projet, nous avons un tableau de bord d'analytique en temps r√©el qui se met √† jour en continu en fonction des flux de donn√©es entrants. L'ensemble du pipeline, de l'ingestion des donn√©es √† la visualisation, d√©montre comment les technologies modernes de big data peuvent √™tre utilis√©es pour la prise de d√©cision et la surveillance en temps r√©el, une exigence essentielle dans les environnements ax√©s sur les donn√©es d'aujourd'hui. Ce projet am√©liore votre compr√©hension de l'architecture des donn√©es en streaming, du traitement avec Spark et de la cr√©ation de tableaux de bord perspicaces pour l'analytique en temps r√©el.

---

## Technologies Utilis√©es
- **Yahoo Finance** : Pour l'acquisition des donn√©es boursi√®res en temps r√©el.
- **Kafka** : Pour l'ingestion des donn√©es en streaming.
- **Zookeeper** : Pour la coordination des services Kafka.
- **Spark** : Pour le traitement des donn√©es en temps r√©el.
- **InfluxDB** : Pour le stockage des donn√©es temporelles.
- **Grafana** : Pour la visualisation des donn√©es en temps r√©el.
- **Docker Compose** : Pour la gestion et l'orchestration des conteneurs.

---

## Comment D√©marrer
1. **Cloner le d√©p√¥t** :
   ```bash
   git clone https://github.com/votre-repo/projet-big-data.git
   cd projet-big-data
   ```
2. **D√©marrer les services avec Docker Compose** :
   ```bash
   docker-compose up -d --build
   ```
3. **Acc√©der au tableau de bord Grafana** :
   Ouvrez votre navigateur et acc√©dez √† `http://localhost:3000` pour visualiser les donn√©es en temps r√©el.

---

## Contribution
Les contributions sont les bienvenues ! Veuillez ouvrir une issue ou soumettre une pull request pour toute am√©lioration ou correction.

---

## Licence
Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

---

